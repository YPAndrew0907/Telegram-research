{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hBowC3JUyXcy",
    "outputId": "edb3d59c-4515-42e5-ae64-83fd081e2fd0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: telethon in /opt/miniconda3/lib/python3.12/site-packages (1.40.0)\n",
      "Requirement already satisfied: pandas in /opt/miniconda3/lib/python3.12/site-packages (2.2.2)\n",
      "Requirement already satisfied: requests in /opt/miniconda3/lib/python3.12/site-packages (2.32.3)\n",
      "Requirement already satisfied: langdetect in /opt/miniconda3/lib/python3.12/site-packages (1.0.9)\n",
      "Requirement already satisfied: pyaes in /opt/miniconda3/lib/python3.12/site-packages (from telethon) (1.6.1)\n",
      "Requirement already satisfied: rsa in /opt/miniconda3/lib/python3.12/site-packages (from telethon) (4.9)\n",
      "Requirement already satisfied: numpy>=1.26.0 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /opt/miniconda3/lib/python3.12/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/miniconda3/lib/python3.12/site-packages (from requests) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/miniconda3/lib/python3.12/site-packages (from requests) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/miniconda3/lib/python3.12/site-packages (from requests) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/miniconda3/lib/python3.12/site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: six in /opt/miniconda3/lib/python3.12/site-packages (from langdetect) (1.16.0)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/miniconda3/lib/python3.12/site-packages (from rsa->telethon) (0.6.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install telethon pandas requests langdetect\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FMPetDnuEL_a",
    "outputId": "bb13a890-d08c-4ba5-bcdc-9c2cd5ed6344"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in /opt/miniconda3/lib/python3.12/site-packages (1.1.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VFIAy13PHt80",
    "outputId": "41d84001-1d7e-4a59-ab43-a68e3f86f5b7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nest_asyncio in /opt/miniconda3/lib/python3.12/site-packages (1.6.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install nest_asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "QXdS3FUDHvyt"
   },
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rRnvbW8UdykJ",
    "outputId": "f192320a-f469-4640-b498-8b16e23a1324"
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive', force_remount=True)\n",
    "except ModuleNotFoundError:\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "Cf2Q2pXXC4ZM"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os, json, csv, time, re\n",
    "import asyncio, requests, pandas as pd\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "from urllib.parse import urlparse\n",
    "from langdetect import detect, DetectorFactory\n",
    "DetectorFactory.seed=0\n",
    "load_dotenv()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "oGRmc41x_UlG"
   },
   "outputs": [],
   "source": [
    "from telethon import TelegramClient, errors\n",
    "from telethon.tl.functions.channels import JoinChannelRequest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "OMcGFBPF_UoF"
   },
   "outputs": [],
   "source": [
    "from telethon.sync import TelegramClient\n",
    "from getpass import getpass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_ID  = 24527187                       # int is OK\n",
    "API_HASH = '8a012769064c0218d779c9e23e45fdb0'\n",
    "PHONE    = '+18573343025'\n",
    "\n",
    "import os\n",
    "os.environ[\"API_ID\"]   = str(API_ID)      # must be strings\n",
    "os.environ[\"API_HASH\"] = API_HASH\n",
    "os.environ[\"PHONE\"]    = PHONE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "_MchyQTGC8IQ"
   },
   "outputs": [],
   "source": [
    "# expects API_ID, API_HASH, and PHONE in the environment\n",
    "API_ID = os.getenv(\"API_ID\")\n",
    "API_HASH = os.getenv(\"API_HASH\")\n",
    "PHONE = os.getenv(\"PHONE\")\n",
    "if not all([API_ID, API_HASH, PHONE]):\n",
    "    raise RuntimeError(\"API_ID, API_HASH and PHONE environment variables must be set\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "ykINbo9OxNpF"
   },
   "outputs": [],
   "source": [
    "PROGRESS_JSON = os.getenv('PROGRESS_JSON', '/content/drive/MyDrive/telegram/progress.json')\n",
    "RAW_CSV = os.getenv('RAW_CSV', '/content/drive/MyDrive/telegram/messages.csv')\n",
    "CLEAN_CSV = os.getenv('CLEAN_CSV', '/content/drive/MyDrive/telegram/cleaned.csv')\n",
    "SESSION_NAME = os.getenv('SESSION_NAME', 'tg_session')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "YYpOd88Gv4Mg"
   },
   "outputs": [],
   "source": [
    "BFS_HOPS         = 2     # how many BFS layers\n",
    "BFS_PER_CH_LIMIT = 400   # how many msgs to scan for forwards each discovered channel\n",
    "BFS_MIN_SUBS     = 500   # subscriber threshold\n",
    "BFS_LANG_SAMPLE  = 15    # how many msgs we sample for English\n",
    "BFS_EN_RATIO     = 0.5   # 50% must be English\n",
    "BFS_FWD_MIN      = 1     # min forwards needed to count a channel\n",
    "BFS_INCLUDE_MENTIONS = False  # parse @username / t.me links\n",
    "BFS_TOPIC_KEYWORDS = []       # keywords to filter topics\n",
    "BFS_TOPIC_RATIO   = 0         # ratio threshold for keyword matches\n",
    "BFS_TOPIC_SAMPLE  = 20        # messages sampled for topic ratio\n",
    "BFS_MAX_DORMANT_DAYS = 0      # ignore channels dormant this many days\n",
    "BFS_PAUSE_SEC     = 0         # optional delay between API calls"
  ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ba2Vaw21xPEj"
   },
   "outputs": [],
   "source": [
    "channels_df = pd.read_csv('telegram_misinformation_channels_full.csv')\n",
    "def _parse_subs(s):\n",
    "    s = str(s).replace('+', '').strip()\n",
    "    mult = 1\n",
    "    if s.lower().endswith('k'):\n",
    "        mult = 1000\n",
    "        s = s[:-1]\n",
    "    elif s.lower().endswith('m'):\n",
    "        mult = 1000000\n",
    "        s = s[:-1]\n",
    "    try:\n",
    "        return int(float(s) * mult)\n",
    "    except ValueError:\n",
    "        return 0\n",
    "channels_df['subs_num'] = channels_df['Subscribers'].apply(_parse_subs)\n",
    "seed_usernames = channels_df['Username'].tolist()\n",
    "FOLLOWERS_DICT = channels_df.set_index('Username')['subs_num'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "zIi_m0JbdyX5"
   },
   "outputs": [],
   "source": [
    "CHANNELS = seed_usernames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "Bdu3oFp__UrI"
   },
   "outputs": [],
   "source": [
    "client=TelegramClient(SESSION_NAME,API_ID,API_HASH)\n",
    "def load_progress():\n",
    "  if os.path.exists(PROGRESS_JSON):\n",
    "    with open(PROGRESS_JSON,'r')as f:return json.load(f)\n",
    "  return {}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "XlaWF6Z0AY6-"
   },
   "outputs": [],
   "source": [
    "def save_progress(d):\n",
    "  os.makedirs(os.path.dirname(PROGRESS_JSON),exist_ok=True)\n",
    "  with open(PROGRESS_JSON,'w')as f:json.dump(d,f)\n",
    "  print(\"Progress saved.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "4nOQuxbgAY8k"
   },
   "outputs": [],
   "source": [
    "def append_header_if_needed():\n",
    "  ex=os.path.exists(RAW_CSV)\n",
    "  os.makedirs(os.path.dirname(RAW_CSV),exist_ok=True)\n",
    "  if not ex:\n",
    "    with open(RAW_CSV,'w',newline='',encoding='utf-8')as f:\n",
    "      csv.writer(f).writerow(['channel','msg_id','date','text','fwd_from','fwd_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "HoqHVl86E-_U"
   },
   "outputs": [],
   "source": [
    "async def join_if_needed(ent):\n",
    "  if getattr(ent,'megagroup',False):\n",
    "    try:await client(JoinChannelRequest(ent))\n",
    "    except:pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "5pQiuvbeE_Ax"
   },
   "outputs": [],
   "source": [
    "async def scrape_channel(name,last_id):\n",
    "  try:ent=await client.get_entity(name)\n",
    "  except Exception as e:print(\"Skip\",name,e);return last_id\n",
    "  await join_if_needed(ent);mx=last_id;cnt=0\n",
    "  async for msg in client.iter_messages(ent,min_id=last_id,reverse=False):\n",
    "    if BFS_PAUSE_SEC:\n",
    "      await asyncio.sleep(BFS_PAUSE_SEC)\n",
    "    cnt+=1;mx=max(mx,msg.id);fw,fwid=None,None\n",
    "    if msg.forward:\n",
    "      if msg.forward.chat:fw=msg.forward.chat.title or msg.forward.chat.username;fwid=getattr(msg.forward.chat,'id',None)\n",
    "      elif msg.forward.sender:fw=msg.forward.sender.first_name or msg.forward.sender.username or'Private';fwid=getattr(msg.forward.sender,'id',None)\n",
    "    with open(RAW_CSV,'a',newline='',encoding='utf-8')as f:\n",
    "      csv.writer(f).writerow([name,msg.id,msg.date,msg.text or'',fw,fwid])\n",
    "  print(name,\"+%d msgs\"%cnt,\"up to\",mx);return mx\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "Fk_TBzdwE_G9"
   },
   "outputs": [],
   "source": [
    "def run_scrape():\n",
    "  asyncio.run(scrape_once())\n",
    "  print(\"Scraping done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "EWBJBeXIE_Jy"
   },
   "outputs": [],
   "source": [
    "def deduplicate(messages):\n",
    "  out=[];seen=set()\n",
    "  for m in messages:\n",
    "    k=(m.get('fwd_id'),m.get('text'))\n",
    "    if m.get('fwd_id'):\n",
    "      if k in seen:continue\n",
    "      seen.add(k)\n",
    "    out.append(m)\n",
    "  return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "s2kMEf60E_MH"
   },
   "outputs": [],
   "source": [
    "def unshorten_url(u,t=5):\n",
    "  try:return requests.head(u,allow_redirects=True,timeout=t).url\n",
    "  except:return u\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "5S7R0ES3E_O1"
   },
   "outputs": [],
   "source": [
    "def expand_and_extract(m):\n",
    "  txt=m['text'];urls=re.findall(r'https?://\\S+',txt)\n",
    "  dom=set()\n",
    "  for u in urls:\n",
    "    fin=unshorten_url(u);d=urlparse(fin).netloc\n",
    "    dom.add(d)\n",
    "    txt=txt.replace(u,fin)\n",
    "  m['text']=txt;m['domains']=list(dom);return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "aFUAEBWiE_TT"
   },
   "outputs": [],
   "source": [
    "def is_english(txt):\n",
    "  if not txt.strip():return False\n",
    "  try:return(detect(txt)=='en')\n",
    "  except:return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "xvy8iJ-HE_Vn"
   },
   "outputs": [],
   "source": [
    "def anonymize(m,user_map):\n",
    "  if m.get('fwd_id')and m['fwd_from']and not str(m['fwd_from']).startswith(('Channel','@')):\n",
    "    if m['fwd_id'] not in user_map:user_map[m['fwd_id']]=f\"User{len(user_map)+1}\"\n",
    "    m['fwd_from']=user_map[m['fwd_id']];m['fwd_id']=None\n",
    "  m['text']=re.sub(r'@[\\w\\d_]+','@USER',m['text'])\n",
    "  return m\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "XuQE2tRRFPeo"
   },
   "outputs": [],
   "source": [
    "def preprocess_data():\n",
    "  if not os.path.exists(RAW_CSV):print(\"No raw CSV.\");return\n",
    "  df=pd.read_csv(RAW_CSV,names=['chan','msg_id','date','text','fwd_from','fwd_id'],header=0)\n",
    "  msgs=df.to_dict('records');msgs=deduplicate(msgs)\n",
    "  out=[];umap={}\n",
    "  for m in msgs:\n",
    "    m=expand_and_extract(m)\n",
    "    if is_english(m['text']):m=anonymize(m,umap);out.append(m)\n",
    "  pd.DataFrame(out).to_csv(CLEAN_CSV,index=False)\n",
    "  print(f\"Saved {len(out)} cleaned msgs to {CLEAN_CSV}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "Ir_L4HSPdya5"
   },
   "outputs": [],
   "source": [
    "# Load existing progress data and merge new seeds\n",
    "progress = load_progress()\n",
    "for username in seed_usernames:\n",
    "    if username not in progress:\n",
    "        progress[username] = 0  # mark as not yet scraped\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "# Where should we store run-time artefacts?\n",
    "WORKDIR = Path(os.getenv(\"TG_WORKDIR\", Path.cwd() / \"telegram_data\"))\n",
    "WORKDIR.mkdir(parents=True, exist_ok=True)   # makes ./telegram_data if absent\n",
    "\n",
    "PROGRESS_JSON = WORKDIR / \"progress.json\"\n",
    "RAW_CSV       = WORKDIR / \"messages.csv\"\n",
    "CLEAN_CSV     = WORKDIR / \"cleaned.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "qocb8QV2dyg3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress saved.\n"
     ]
    }
   ],
   "source": [
    "# Persist updated progress\n",
    "save_progress(progress)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "h8KS4Vdgv4Pu"
   },
   "outputs": [],
   "source": [
    "from langdetect import detect\n",
    "async def _en_ratio(ent, sample=BFS_LANG_SAMPLE):\n",
    "    en = 0\n",
    "    async for m in client.iter_messages(ent, limit=sample):\n",
    "        t = (m.message or '').strip()\n",
    "        if t:\n",
    "            try:  en += detect(t)=='en'\n",
    "            except: pass\n",
    "    return 0 if not sample else en/sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "d5gZoB5XwXYm"
   },
   "outputs": [],
   "source": [
    "from telethon.tl.types import PeerChannel\n",
    "async def _forward_sources(ent, limit=BFS_PER_CH_LIMIT):\n",
    "    counts = {}\n",
    "    async for m in client.iter_messages(ent, limit=limit):\n",
    "        if BFS_PAUSE_SEC:\n",
    "            await asyncio.sleep(BFS_PAUSE_SEC)\n",
    "        fwd = m.forward\n",
    "        if not fwd:\n",
    "            continue\n",
    "        pc = fwd.chat or fwd.original_fwd\n",
    "        if isinstance(pc, PeerChannel):\n",
    "            cid = pc.channel_id\n",
    "            counts[cid] = counts.get(cid, 0) + 1\n",
    "    return {c for c, n in counts.items() if n >= BFS_FWD_MIN}\n",

    "MENTION_RE = re.compile(r'@([\\w\\d_]{5,32})|t\\.me/([\\w\\d_]{5,32})', re.I)\n",

    "async def _mention_sources(ent, limit=BFS_PER_CH_LIMIT):\n",
    "    src = set()\n",
    "    if not BFS_INCLUDE_MENTIONS:\n",
    "        return src\n",
    "    async for m in client.iter_messages(ent, limit=limit):\n",
    "        if BFS_PAUSE_SEC:\n",
    "            await asyncio.sleep(BFS_PAUSE_SEC)\n",
    "        text = (m.message or '')\n",
    "        for a, b in MENTION_RE.findall(text):\n",
    "            name = a or b\n",
    "            if name:\n",
    "                src.add(name.lstrip('@'))\n",
    "    return src\n",

    "async def _topic_ratio(ent, keywords, sample=BFS_TOPIC_SAMPLE):\n",
    "    if not keywords:\n",
    "        return 1.0\n",
    "    pat = re.compile('|'.join(re.escape(k) for k in keywords), re.I)\n",
    "    hits = 0\n",
    "    tot = 0\n",
    "    async for m in client.iter_messages(ent, limit=sample):\n",
    "        if BFS_PAUSE_SEC:\n",
    "            await asyncio.sleep(BFS_PAUSE_SEC)\n",
    "        text = (m.message or '')\n",
    "        if text.strip():\n",
    "            tot += 1\n",
    "            if pat.search(text):\n",
    "                hits += 1\n",
    "    return 0 if not tot else hits / tot\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 228
    },
    "id": "eFK9klEFwXbm",
    "outputId": "f6a4f455-e91c-4f60-9956-8dd45ba63c5f"
   },
   "outputs": [],
   "source": [
    "async def _is_valid(ent):\n",
    "    username = (getattr(ent, 'username', '') or '').strip()\n",
    "    count = FOLLOWERS_DICT.get(username, 0)\n",
    "    if count == 0:\n",
    "        try:\n",
    "            full = await client(GetFullChannelRequest(ent))\n",
    "            count = getattr(full.full_chat, 'participants_count', 0)\n",
    "        except Exception:\n",
    "            count = 0\n",
    "    if count < BFS_MIN_SUBS:\n",
    "        return False\n",
    "    if BFS_MAX_DORMANT_DAYS:\n",
    "        try:\n",
    "            async for m in client.iter_messages(ent, limit=1):\n",
    "                if BFS_PAUSE_SEC:\n",
    "                    await asyncio.sleep(BFS_PAUSE_SEC)\n",
    "                if m.date:\n",
    "                    days = (datetime.utcnow() - m.date.replace(tzinfo=None)).days\n",
    "                    if days > BFS_MAX_DORMANT_DAYS:\n",
    "                        return False\n",
    "                break\n",
    "        except Exception:\n",
    "            return False\n",
    "    if BFS_TOPIC_KEYWORDS and BFS_TOPIC_RATIO:\n",
    "        try:\n",
    "            if await _topic_ratio(ent, BFS_TOPIC_KEYWORDS, BFS_TOPIC_SAMPLE) < BFS_TOPIC_RATIO:\n",
    "                return False\n",
    "        except Exception:\n",
    "            return False\n",
    "    try:\n",
    "        return (await _en_ratio(ent)) >= BFS_EN_RATIO\n",
    "    except Exception:\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "wjHw18VOwXeS"
   },
   "outputs": [],
   "source": [
    "async def snowball_discovery():\n",
    "    global CHANNELS\n",
    "    progress = load_progress()\n",
    "    seeds = [c.lstrip('@') for c in CHANNELS]\n",
    "    validated = await discover_bfs(seeds, max_hops=BFS_HOPS)\n",
    "    for v in validated:\n",
    "        if v not in progress:\n",
    "            progress[v] = 0\n",
    "    save_progress(progress)\n",
    "    CHANNELS = list(set(CHANNELS) | set(validated))\n",
    "    print('validated:', len(validated), '| total CHANNELS:', len(CHANNELS))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "zOHfC_v0wXg5"
   },
   "outputs": [],
   "source": [
    "async def scrape_once():\n",
    "    await client.start(phone=PHONE)\n",
    "    await snowball_discovery()          # \u2460  discover / merge\n",
    "    last = load_progress(); append_header_if_needed()\n",
    "    for c in CHANNELS:\n",
    "        last[c] = await scrape_channel(c, last.get(c,0))\n",
    "        if BFS_PAUSE_SEC:\n",
    "            await asyncio.sleep(BFS_PAUSE_SEC)\n",
    "    save_progress(last); await client.disconnect()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "Ly3Z1jugFPhg"
   },
   "outputs": [],
   "source": [
    "def main():\n",
    "  run_scrape()\n",
    "  preprocess_data()\n",
    "  print(\"Done.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Enhanced BFS crawler with forward counting and optional mentions\n",
    "from collections import deque, defaultdict\n",
    "\n",
    "async def discover_bfs(seeds, max_hops=BFS_HOPS):\n",
    "    visited = set(seeds)\n",
    "    queue = deque((s, 0) for s in seeds)\n",
    "    validated = set(seeds)\n",
    "    while queue:\n",
    "        username, hop = queue.popleft()\n",
    "        if hop >= max_hops:\n",
    "            continue\n",
    "        try:\n",
    "            ent = await client.get_entity(username)\n",
    "        except Exception:\n",
    "            continue\n",
    "        if not await _is_valid(ent):\n",
    "            continue\n",
    "        fwd = await _forward_sources(ent)\n",
    "        mentions = await _mention_sources(ent)\n",
    "        for cid in fwd:\n",
    "            try:\n",
    "                ch = await client.get_entity(PeerChannel(cid))\n",
    "                uname = ch.username\n",
    "                if uname and uname not in visited:\n",
    "                    visited.add(uname)\n",
    "                    queue.append((uname, hop + 1))\n",
    "                    validated.add(uname)\n",
    "            except Exception:\n",
    "                pass\n",
    "            if BFS_PAUSE_SEC:\n",
    "                await asyncio.sleep(BFS_PAUSE_SEC)\n",
    "        for uname in mentions:\n",
    "            if uname not in visited:\n",
    "                visited.add(uname)\n",
    "                queue.append((uname, hop + 1))\n",
    "                validated.add(uname)\n",
    "            if BFS_PAUSE_SEC:\n",
    "                await asyncio.sleep(BFS_PAUSE_SEC)\n",
    "    return validated\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7dYlGjV_INa4"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "OGndW8SXFPkE"
   },
   "outputs": [],
   "source": [
    "# main()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
